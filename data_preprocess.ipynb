{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "{'object_id': 'tiktok_live@7364652435727567662_1714718428000', 'url_list': ['http://lf16-fcdn-timeshift.tiktokcdn-us.com/obj/fcdn-tiktok-tx/71465123841433646761/push-rtmp-f5-tt01.fcdn.us.tiktokv.com/stage/stream-3573837222899614640/20240503064015749.jpg', 'http://p-lab-va.bytedance.net/obj/post-meta-va/71465123841433646761/push-rtmp-f5-tt01.fcdn.us.tiktokv.com/stage/stream-3573837222899614640/tiktok-v2/20240503064017888.jpg', 'http://p-lab-va.bytedance.net/obj/post-meta-va/71465123841433646761/push-rtmp-f5-tt01.fcdn.us.tiktokv.com/stage/stream-3573837222899614640/tiktok-v2/20240503064019939.jpg', 'http://p-lab-va.bytedance.net/obj/post-meta-va/71465123841433646761/push-rtmp-f5-tt01.fcdn.us.tiktokv.com/stage/stream-3573837222899614640/tiktok-v2/20240503064021931.jpg', 'http://p-lab-va.bytedance.net/obj/post-meta-va/71465123841433646761/push-rtmp-f5-tt01.fcdn.us.tiktokv.com/stage/stream-3573837222899614640/tiktok-v2/20240503064023873.jpg', 'http://p-lab-va.bytedance.net/obj/post-meta-va/71465123841433646761/push-rtmp-f5-tt01.fcdn.us.tiktokv.com/stage/stream-3573837222899614640/tiktok-v2/20240503064025851.jpg', 'http://p-lab-va.bytedance.net/obj/post-meta-va/71465123841433646761/push-rtmp-f5-tt01.fcdn.us.tiktokv.com/stage/stream-3573837222899614640/tiktok-v2/20240503064027885.jpg', 'http://p-lab-va.bytedance.net/obj/post-meta-va/71465123841433646761/push-rtmp-f5-tt01.fcdn.us.tiktokv.com/stage/stream-3573837222899614640/tiktok-v2/20240503064027885.jpg', 'http://p-lab-va.bytedance.net/obj/post-meta-va/71465123841433646761/push-rtmp-f5-tt01.fcdn.us.tiktokv.com/stage/stream-3573837222899614640/tiktok-v2/20240503064027885.jpg', 'http://p-lab-va.bytedance.net/obj/post-meta-va/71465123841433646761/push-rtmp-f5-tt01.fcdn.us.tiktokv.com/stage/stream-3573837222899614640/tiktok-v2/20240503064027885.jpg']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"/opt/tiger/LLM/face/data/face_pos.jsonl\") as f:\n",
    "    data = []\n",
    "    for line in f.readlines():\n",
    "        data.append(json.loads(line))\n",
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['object_id', 'image_urls', 'room_id']\n",
      "shape: (10, 3)\n",
      "┌─────────────────────────────────┬─────────────────────────────────┬─────────────────────┐\n",
      "│ object_id                       ┆ image_urls                      ┆ room_id             │\n",
      "│ ---                             ┆ ---                             ┆ ---                 │\n",
      "│ str                             ┆ str                             ┆ i64                 │\n",
      "╞═════════════════════════════════╪═════════════════════════════════╪═════════════════════╡\n",
      "│ tiktok_live@735665948258953088… ┆ [{\"offline_uri\":\"http://webcas… ┆ 7356659482589530886 │\n",
      "│ tiktok_live@735665948258953088… ┆ [{\"offline_uri\":\"http://webcas… ┆ 7356659482589530886 │\n",
      "│ tiktok_live@735776848083165466… ┆ [{\"offline_uri\":\"http://webcas… ┆ 7357768480831654662 │\n",
      "│ tiktok_live@735776848083165466… ┆ [{\"offline_uri\":\"http://webcas… ┆ 7357768480831654662 │\n",
      "│ tiktok_live@735934514826785873… ┆ [{\"offline_uri\":\"http://tosv.t… ┆ 7359345148267858731 │\n",
      "│ tiktok_live@735934514826785873… ┆ [{\"offline_uri\":\"http://tosv.t… ┆ 7359345148267858731 │\n",
      "│ tiktok_live@735945814054081616… ┆ [{\"offline_uri\":\"http://webcas… ┆ 7359458140540816161 │\n",
      "│ tiktok_live@735945814054081616… ┆ [{\"offline_uri\":\"http://webcas… ┆ 7359458140540816161 │\n",
      "│ tiktok_live@735992846435295515… ┆ [{\"offline_uri\":\"http://webcas… ┆ 7359928464352955154 │\n",
      "│ tiktok_live@735992846435295515… ┆ [{\"offline_uri\":\"http://webcas… ┆ 7359928464352955154 │\n",
      "└─────────────────────────────────┴─────────────────────────────────┴─────────────────────┘\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "data = pl.read_csv(\"/opt/tiger/labeled_pos_2000/part-00000-81a3d2d2-ed66-4051-96ca-b6bf309f0ccf-c000.csv\")\n",
    "print(data.columns)\n",
    "print(data.head(10))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_0</th><th>column_1</th><th>column_2</th></tr><tr><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;tiktok_live@735665948258953088…</td><td>&quot;[&quot;http://p-lab-va.bytedance.ne…</td><td>7356659482589530886</td></tr><tr><td>&quot;tiktok_live@735665948258953088…</td><td>&quot;[&quot;http://p-lab-va.bytedance.ne…</td><td>7356659482589530886</td></tr><tr><td>&quot;tiktok_live@735776848083165466…</td><td>&quot;[&quot;http://p-lab-va.bytedance.ne…</td><td>7357768480831654662</td></tr><tr><td>&quot;tiktok_live@735776848083165466…</td><td>&quot;[&quot;http://p-lab-va.bytedance.ne…</td><td>7357768480831654662</td></tr><tr><td>&quot;tiktok_live@735934514826785873…</td><td>&quot;[&quot;http://p-lab-va.bytedance.ne…</td><td>7359345148267858731</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────────────────────────┬─────────────────────────────────┬─────────────────────┐\n",
       "│ column_0                        ┆ column_1                        ┆ column_2            │\n",
       "│ ---                             ┆ ---                             ┆ ---                 │\n",
       "│ str                             ┆ str                             ┆ i64                 │\n",
       "╞═════════════════════════════════╪═════════════════════════════════╪═════════════════════╡\n",
       "│ tiktok_live@735665948258953088… ┆ [\"http://p-lab-va.bytedance.ne… ┆ 7356659482589530886 │\n",
       "│ tiktok_live@735665948258953088… ┆ [\"http://p-lab-va.bytedance.ne… ┆ 7356659482589530886 │\n",
       "│ tiktok_live@735776848083165466… ┆ [\"http://p-lab-va.bytedance.ne… ┆ 7357768480831654662 │\n",
       "│ tiktok_live@735776848083165466… ┆ [\"http://p-lab-va.bytedance.ne… ┆ 7357768480831654662 │\n",
       "│ tiktok_live@735934514826785873… ┆ [\"http://p-lab-va.bytedance.ne… ┆ 7359345148267858731 │\n",
       "└─────────────────────────────────┴─────────────────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "\n",
    "def trans2zeus_feature_pos(row):\n",
    "    url_list = []\n",
    "    image_urls = json.loads(row[1])\n",
    "    for img_dict in image_urls:\n",
    "        img_url = img_dict['offline_uri']\n",
    "        img_url = img_url.replace('tosv.byted.org', 'p-lab-va.bytedance.net').replace('tosv.tiktokd.org', 'p-lab-va.bytedance.net').replace('post-meta-tx', 'post-meta-va').replace('fcdn-live-triage-audit-tx', 'fcdn-live-triage-audit-va')\n",
    "        # 新规则\n",
    "        img_url = img_url.replace('http://webcast-review-tos-va.byteintl.net/obj/post-meta-va', 'http://p-lab-va.bytedance.net/obj/post-meta-va').replace('http://webcast-review-tos.byteintl.net', 'http://p-lab-va.bytedance.net').replace('post-meta-euttp', 'post-meta-va').replace('fcdn-tiktok-euttp', 'fcdn-tiktok').replace('fcdn-live-triage-audit-euttp', 'fcdn-live-triage-audit-va')\n",
    "        img_url = img_url.replace('tosv-ttp2.tiktokd.org', 'p-lab-va.bytedance.net')\n",
    "        url_list.append(img_url)\n",
    "\n",
    "    return (row[0], json.dumps(url_list), row[2])\n",
    "\n",
    "# 应用转换函数到Polars DataFrame的每一行\n",
    "feature_list = data.map_rows(trans2zeus_feature_pos)\n",
    "feature_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['object_id', 'image_urls', 'room_id']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename = {\"column_0\":\"object_id\", \"column_1\":'image_urls', \"column_2\":\"room_id\"}\n",
    "feature_list = feature_list.rename(rename)\n",
    "feature_list.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "feature_list = feature_list.to_dicts()\n",
    "processed_df = []\n",
    "for i in range(0, len(feature_list), 2):\n",
    "    tmp = {}\n",
    "    tmp[\"room_id\"] = feature_list[i][\"room_id\"]\n",
    "    tmp[\"object1\"] = feature_list[i][\"object_id\"]\n",
    "    tmp[\"urls1\"] = feature_list[i][\"image_urls\"]\n",
    "    tmp[\"object2\"] = feature_list[i+1][\"object_id\"]\n",
    "    tmp[\"urls2\"] = feature_list[i+1][\"image_urls\"]\n",
    "    processed_df.append(tmp)\n",
    "print(len(processed_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'room_id': 7356659482589530886, 'object1': 'tiktok_live@7356659482589530886_1714780789000', 'urls1': '[\"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240503235931548.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240503235933578.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240503235935557.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240503235937558.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240503235939562.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240503235941680.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240503235943547.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240503235945585.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240503235948418.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240503235949639.jpg\"]', 'object2': 'tiktok_live@7356659482589530886_1714780809000', 'urls2': '[\"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240503235951816.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240503235953546.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240503235955573.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240503235957556.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240503235959610.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240504000001583.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240504000003673.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240504000005565.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240504000007602.jpg\", \"http://p-lab-va.bytedance.net/obj/post-meta-va/7654592258592283018/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997251568003187449/tiktok-v2/20240504000009964.jpg\"]'}\n"
     ]
    }
   ],
   "source": [
    "print(processed_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/processed_pair_face.json\", \"r\") as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genericpath import exists\n",
    "import requests\n",
    "import uuid\n",
    "import os\n",
    "root = \"/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/second_stage_train_imgs\"\n",
    "if not os.path.exists(f'{root}'): os.mkdir(f'{root}')\n",
    "def get_img_roomid(data):\n",
    "    if not os.path.exists(f'{root}/{data[\"room_id\"]}/'): \n",
    "        os.mkdir(f'{root}/{data[\"room_id\"]}/')\n",
    "        os.mkdir(f'{root}/{data[\"room_id\"]}/{data[\"object1\"]}')\n",
    "        os.mkdir(f'{root}/{data[\"room_id\"]}/{data[\"object2\"]}')\n",
    "    else: return None\n",
    "    urls1, urls2 = json.loads(data[\"urls1\"]), json.loads(data[\"urls2\"])\n",
    "    for url in urls1:\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            # 检查请求是否成功\n",
    "            if response.status_code == 200:\n",
    "                # 使用uuid生成唯一的文件名\n",
    "                file_name = str(uuid.uuid4()) + '.jpg'\n",
    "                # 构建文件保存路径\n",
    "                file_path = os.path.join(f'{root}/{data[\"room_id\"]}/{data[\"object1\"]}', file_name)\n",
    "                # 将响应内容写入文件\n",
    "                with open(file_path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "            else:\n",
    "                print('图片下载失败，状态码:', response.status_code)\n",
    "        except Exception as e:\n",
    "            print(f'图片下载失败，错误：{e}')\n",
    "\n",
    "    for url in urls2:\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            # 检查请求是否成功\n",
    "            if response.status_code == 200:\n",
    "                # 使用uuid生成唯一的文件名\n",
    "                file_name = str(uuid.uuid4()) + '.jpg'\n",
    "                # 构建文件保存路径\n",
    "                file_path = os.path.join(f'{root}/{data[\"room_id\"]}/{data[\"object2\"]}', file_name)\n",
    "                # 将响应内容写入文件\n",
    "                with open(file_path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "            else:\n",
    "                print('图片下载失败，状态码:', response.status_code)\n",
    "        except Exception as e:\n",
    "            print(f'图片下载失败，错误：{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将转换后的数据写入文件\n",
    "save_df = json.dumps(processed_df, ensure_ascii=False, indent=4)\n",
    "with open(\"/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/processed_pair_face.json\", \"w\") as f:\n",
    "    f.write(save_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "base = \"/opt/tiger/url_processed_json/\"\n",
    "paths = os.listdir(base)\n",
    "data = []\n",
    "for path in paths:\n",
    "    with open(base+path) as f:\n",
    "        for line in f.readlines():\n",
    "            data.append(json.loads(line))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'object_id': 'tiktok_live@7362733341105998597_1714780867000', 'room_id': '7362733341105998597', 'url_list': ['http://lp10-va01.tiktokcdn.com/stage/stream-2997346472147288825/1714780559000.jpg', 'http://lp10-va01.tiktokcdn.com/stage/stream-2997346472147288825/1714780563000.jpg', 'http://lp10-va01.tiktokcdn.com/stage/stream-2997346472147288825/1714780567000.jpg', 'http://webcast-review-tos-va.byteintl.net/obj/thunder-audit-backup-us/5807046414045719637/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997346472147288825/20240503235613947.jpeg', 'http://lp10-va01.tiktokcdn.com/stage/stream-2997346472147288825/1714780685000.jpg', 'http://lp10-va01.tiktokcdn.com/stage/stream-2997346472147288825/1714780689000.jpg', 'http://webcast-review-tos-va.byteintl.net/obj/thunder-audit-backup-us/5807046414045719637/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997346472147288825/20240503235814539.jpeg', 'http://webcast-review-tos-va.byteintl.net/obj/thunder-audit-backup-us/5807046414045719637/push-rtmp-l10-va01.tiktokcdn.com/stage/stream-2997346472147288825/20240503235905677.jpeg', 'http://lp10-va01.tiktokcdn.com/stage/stream-2997346472147288825/1714780863000.jpg', 'http://lp10-va01.tiktokcdn.com/stage/stream-2997346472147288825/1714780867000.jpg']}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "def get_img(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        # 检查请求是否成功\n",
    "        if response.status_code == 200:\n",
    "            # 使用uuid生成唯一的文件名\n",
    "            file_name = str(uuid.uuid4()) + '.jpg'\n",
    "            # 构建文件保存路径\n",
    "            file_path = os.path.join('/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/test_imgs/', file_name)\n",
    "            \n",
    "            # 将响应内容写入文件\n",
    "            with open(file_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            return file_path  # 返回文件保存的路径\n",
    "\n",
    "        else:\n",
    "            print('图片下载失败，状态码:', response.status_code)\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'图片下载失败，错误：{e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genericpath import exists\n",
    "import requests\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "def get_test_img(data):\n",
    "    if not os.path.exists(f'/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/test_imgs/{data[\"room_id\"]}/'): os.mkdir(f'/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/test_imgs/{data[\"room_id\"]}/')\n",
    "    for url in data[\"url_list\"]:\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            # 检查请求是否成功\n",
    "            if response.status_code == 200:\n",
    "                # 使用uuid生成唯一的文件名\n",
    "                file_name = str(uuid.uuid4()) + '.jpg'\n",
    "                # 构建文件保存路径\n",
    "                file_path = os.path.join(f'/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/test_imgs/{data[\"room_id\"]}/', file_name)\n",
    "                # 将响应内容写入文件\n",
    "                with open(file_path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "            else:\n",
    "                print('图片下载失败，状态码:', response.status_code)\n",
    "        except Exception as e:\n",
    "            print(f'图片下载失败，错误：{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for d in data:\n",
    "    for url in d[\"url_list\"]:\n",
    "        imgs.append(get_img(url))\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from functools import partial\n",
    "\n",
    "# 从数据中提取所有的URL\n",
    "all_urls = []\n",
    "for d in data:\n",
    "    all_urls.extend(d[\"url_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 确保列表中有足够的 URL\n",
    "if len(all_urls) >= 200000:\n",
    "    # 随机选择 10 万个 URL\n",
    "    selected_urls = random.sample(all_urls, 200000)\n",
    "else:\n",
    "    print(\"URL 数量不足 10 万！\")\n",
    "\n",
    "# 现在 selected_urls 包含了随机选择的 10 万个 URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用多进程池来下载图像\n",
    "def download_images(urls):\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        pool.map(get_img, urls)\n",
    "\n",
    "# 调用函数开始多进程下载\n",
    "download_images(selected_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get test imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "# 使用多进程池来下载图像\n",
    "def download_images(data):\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        pool.map(get_img_roomid, data)\n",
    "\n",
    "# 调用函数开始多进程下载\n",
    "download_images(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "tmp = os.listdir(\"/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/second_stage_train_imgs\")\n",
    "print(len(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功解码了10张图像。\n",
      "(1280, 720, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img_array = []\n",
    "for i, img in enumerate(imgs):\n",
    "    # 将字节类型的数据解码成图像数组\n",
    "    img_np = np.frombuffer(img, dtype=np.uint8)  # 首先将字节数据转换为NumPy数组\n",
    "    img_decoded = cv2.imdecode(img_np, cv2.IMREAD_COLOR)  # 然后解码图像\n",
    "    if img_decoded is not None:  # 检查解码是否成功\n",
    "        img_array.append(img_decoded)  # 如果解码成功，添加到列表中\n",
    "    else:\n",
    "        print(f\"解码索引为{i}的图像失败\")\n",
    "\n",
    "# 检查是否所有图像都解码成功\n",
    "if len(img_array) == len(imgs):\n",
    "    print(f\"成功解码了{len(img_array)}张图像。\")\n",
    "    for i, img in enumerate(img_array):\n",
    "        # 将图像数组保存为JPG格式的文件\n",
    "        cv2.imwrite(f'/opt/tiger/LLM/face/data/downloaded_imgs/{i}.jpg', img)\n",
    "else:\n",
    "    print(f\"总共有{len(imgs)}张图像，但只成功解码了{len(img_array)}张。\")\n",
    "\n",
    "print(img_array[0].shape)  # 打印第一张图像的形状，如果它存在"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取人脸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/euler/hook.py:26: EulerDeprecatedWarning: Importing a thrift file without user's explicit intention had caused various troubles and is deprecated by now. Implicit installation of the import hook will be removed in Euler 2.0.\n",
      "Either state your intention by calling `euler.install_thrift_import_hook()`, or use `thriftpy2.load()` to manually load thrift files.\n",
      "  warnings.warn(msg, EulerDeprecatedWarning)\n",
      "/usr/local/lib/python3.9/dist-packages/euler/client.py:137: EulerDeprecatedWarning: Don't specify idc in PSM with `sd://p.s.m.service.${IDC}` format, otherwise it will cause abnormal behaviors in MS or Mesh. The right format is `sd://p.s.m?idc=${IDC}`.\n",
      "  warnings.warn(msg, errors.EulerDeprecatedWarning)\n",
      "/usr/local/lib/python3.9/dist-packages/euler/client.py:143: EulerDeprecatedWarning: cluster not specified, by some history reasons, all clusters will be used without mesh mode, but only default cluster will be used in mesh mode. So we highly recommend to specify a cluster (e.g. default), like: `sd://product.service.module?cluster=default` to avoid confuse.\n",
      "  warnings.warn(msg, errors.EulerDeprecatedWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import euler\n",
    "import argparse\n",
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "sys.path.append(\"/opt/tiger/LLM/face\")\n",
    "from fermion_core_thrift import *\n",
    "from base_thrift import *\n",
    "\n",
    "def get_color_map_list(num_classes):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        num_classes (int): number of class\n",
    "    Returns:\n",
    "        color_map (list): RGB color list\n",
    "    \"\"\"\n",
    "    color_map = num_classes * [0, 0, 0]\n",
    "    for i in range(0, num_classes):\n",
    "        j = 0\n",
    "        lab = i\n",
    "        while lab:\n",
    "            color_map[i * 3] |= (((lab >> 0) & 1) << (7 - j))\n",
    "            color_map[i * 3 + 1] |= (((lab >> 1) & 1) << (7 - j))\n",
    "            color_map[i * 3 + 2] |= (((lab >> 2) & 1) << (7 - j))\n",
    "            j += 1\n",
    "            lab >>= 3\n",
    "    color_map = [color_map[i:i + 3] for i in range(0, len(color_map), 3)]\n",
    "    return color_map\n",
    "\n",
    "def preprocess(np_boxes: list[float]):\n",
    "    np_boxes = np.array(np_boxes)\n",
    "    np_boxes = np_boxes.reshape(-1, 6).tolist()\n",
    "    preprocessed_boxes = []\n",
    "    for box in np_boxes:\n",
    "        # 分离类别ID和边界框坐标以及分数\n",
    "        clsid, x1, y1, x2, y2, score = int(box[5]), box[0], box[1], box[2], box[3], box[4]\n",
    "        # 将边界框坐标打包成一个列表\n",
    "        bbox = [x1, y1, x2, y2]\n",
    "        # 将信息添加到新列表中\n",
    "        preprocessed_boxes.append([clsid, score, bbox])\n",
    "    return preprocessed_boxes\n",
    "    \n",
    "def draw_box(im, np_boxes, labels, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        im (PIL.Image.Image): PIL image\n",
    "        np_boxes (np.ndarray): shape:[N,6], N: number of box,\n",
    "                               matix element:[class, score, x_min, y_min, x_max, y_max]\n",
    "        labels (list): labels:['class1', ..., 'classn']\n",
    "        threshold (float): threshold of box\n",
    "    Returns:\n",
    "        im (PIL.Image.Image): visualized image\n",
    "    \"\"\"\n",
    "    np_boxes = preprocess(np_boxes)\n",
    "    draw_thickness = min(im.size) // 320\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    clsid2color = {}\n",
    "    color_list = get_color_map_list(len(labels))\n",
    "    # print(\"np_boxes\", np_boxes)\n",
    "    np_boxes = [\n",
    "        box for box in np_boxes\n",
    "        if box[1] > threshold and box[0] > -1\n",
    "    ]\n",
    "    # np_boxes = np_boxes[expect_boxes, :]\n",
    "\n",
    "    for dt in np_boxes:\n",
    "        clsid, bbox, score = int(dt[0]), dt[2], dt[1]\n",
    "        if clsid not in clsid2color:\n",
    "            clsid2color[clsid] = color_list[clsid]\n",
    "        color = tuple(clsid2color[clsid])\n",
    "        color = (22,222,22)\n",
    "\n",
    "        if len(bbox) == 4:\n",
    "            xmin, ymin, xmax, ymax = bbox\n",
    "            # print('class_id:{:d}, confidence:{:.4f}, left_top:[{:.2f},{:.2f}],'\n",
    "            #       'right_bottom:[{:.2f},{:.2f}]'.format(\n",
    "            #           int(clsid), score, xmin, ymin, xmax, ymax))\n",
    "            # draw bbox\n",
    "            draw.line(\n",
    "                [(xmin, ymin), (xmin, ymax), (xmax, ymax), (xmax, ymin),\n",
    "                 (xmin, ymin)],\n",
    "                width=4,\n",
    "                fill=color)\n",
    "        elif len(bbox) == 8:\n",
    "            x1, y1, x2, y2, x3, y3, x4, y4 = bbox\n",
    "            draw.line(\n",
    "                [(x1, y1), (x2, y2), (x3, y3), (x4, y4), (x1, y1)],\n",
    "                width=2,\n",
    "                fill=color)\n",
    "            xmin = min(x1, x2, x3, x4)\n",
    "            ymin = min(y1, y2, y3, y4)\n",
    "\n",
    "        # draw label\n",
    "        text = \"{} {:.4f}\".format(labels[clsid], score)\n",
    "        tw, th = draw.textsize(text)\n",
    "        draw.rectangle(\n",
    "            [(xmin + 1, ymin - th), (xmin + tw + 1, ymin)], fill=color)\n",
    "        draw.text((xmin + 1, ymin - th), text, fill=(255, 255, 255))\n",
    "    return im\n",
    "\n",
    "def InferImages(file_content, client):\n",
    "    req = InferRequest()\n",
    "    t = Tensor()\n",
    "    t.dtype = DataType.STRING\n",
    "    t.shape = []\n",
    "    t.str_data = [file_content]\n",
    "    req.input = [TensorSet(tensors={\"image\": t})]\n",
    "    resp = client.Infer(req)\n",
    "    # print(resp)\n",
    "    return resp.output[0]  # batch=1, so index 0 is the final result\n",
    "\n",
    "client = euler.Client(FermionCore, 'sd://tns.cv.facedet_offline.service.sg1', timeout=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计有效下载图片数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19630\n"
     ]
    }
   ],
   "source": [
    "root = \"/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/second_stage_train_imgs/\"\n",
    "cnt = 0\n",
    "for d in data:\n",
    "    cnt += len(os.listdir(f'{root}/{d[\"room_id\"]}/{d[\"object1\"]}'))\n",
    "    cnt += len(os.listdir(f'{root}/{d[\"room_id\"]}/{d[\"object2\"]}'))\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSet(tensors={'prob': Tensor(dtype=232, shape=[6], int8_data=[], int16_data=[], int32_data=[], int64_data=[], float_data=[146.1750030517578, 347.8781433105469, 341.25, 637.6218872070312, 0.92626953125, 0.0], str_data=[], data=b'', extra={})}, extra={})\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/downloaded_imgs/00352d75-f266-4625-a742-b02562b6b8ad.jpg\", \"rb\") as f:\n",
    "    img = f.read()\n",
    "    output_tensor = InferImages(img, client)\n",
    "    print(output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_dir = \"/opt/tiger/LLM/face/data/downloaded_imgs\"\n",
    "\n",
    "# for i, img in enumerate(imgs):\n",
    "#     output_tensor = InferImages(img, client)\n",
    "#     np_bbox = np.array(output_tensor.tensors['prob'].float_data)\n",
    "#     bbox_shape = output_tensor.tensors['prob'].shape\n",
    "#     np_bbox = np_bbox.reshape(bbox_shape)\n",
    "#     print(\"np_bbox\",np_bbox)\n",
    "#     if sum(np_bbox)==0: \n",
    "#         print(\"没有人脸\")\n",
    "#         continue\n",
    "#     if len(np_bbox) > 6:\n",
    "#         print(\"多张人脸\")\n",
    "#         continue\n",
    "\n",
    "#     # visualization 可视化对其效果\n",
    "#     from PIL import Image, ImageDraw\n",
    "#     img_np = np.frombuffer(img, dtype=np.uint8)  # 首先将字节数据转换为NumPy数组\n",
    "#     img = cv2.imdecode(img_np, cv2.IMREAD_COLOR)  # 然后解码图像\n",
    "#     # 从 np_bbox 中提取边界框的坐标\n",
    "#     x1, y1, x2, y2 = np_bbox[:4].astype(int)\n",
    "#     # 根据边界框坐标裁剪图像\n",
    "#     cropped_img = img[y1:y2, x1:x2]\n",
    "#     cv2.imwrite(f'/opt/tiger/LLM/face/data/downloaded_imgs/{i}.jpg', cropped_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取 img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一阶段无监督"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import uuid\n",
    "import cv2\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "imgs_dic = \"/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/test_imgs/\"\n",
    "target_path = \"/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/cropped_test_imgs\"\n",
    "# 定义处理单个图像的函数\n",
    "def process_image(paths):\n",
    "    imgs_path = os.listdir(imgs_dic+paths)\n",
    "    os.mkdir(os.path.join(target_path,paths))\n",
    "    for path in imgs_path:\n",
    "        try:\n",
    "            with open(os.path.join(imgs_dic,paths,path), \"rb\") as f:\n",
    "                img = f.read()\n",
    "            if img is None:\n",
    "                raise ValueError(f\"无法读取图像: {path}\")\n",
    "            \n",
    "            output_tensor = InferImages(img, client)\n",
    "            np_bbox = np.array(output_tensor.tensors['prob'].float_data)\n",
    "            bbox_shape = output_tensor.tensors['prob'].shape\n",
    "            np_bbox = np_bbox.reshape(bbox_shape)\n",
    "            if len(np_bbox) != 6:\n",
    "                continue\n",
    "            if sum(np_bbox) == 0:\n",
    "                continue\n",
    "            x1, y1, x2, y2 = np_bbox[:4].astype(int)\n",
    "\n",
    "            from PIL import Image, ImageDraw\n",
    "            img_np = np.frombuffer(img, dtype=np.uint8)  # 首先将字节数据转换为NumPy数组\n",
    "            img = cv2.imdecode(img_np, cv2.IMREAD_COLOR)  # 然后解码图像\n",
    "            cropped_img = img[y1:y2, x1:x2]\n",
    "            \n",
    "            # 使用uuid生成唯一的文件名\n",
    "            # file_name = str(uuid.uuid4()) + '.jpg'\n",
    "            # 保存裁剪后的图像\n",
    "            cv2.imwrite(os.path.join(target_path,paths,path), cropped_img)\n",
    "        except Exception as e:\n",
    "            print(f\"处理图像出错: {path}, 错误: {e}\")\n",
    "\n",
    "# 使用多进程池来并行处理图像\n",
    "def parallel_process_images(paths):\n",
    "    with Pool() as pool:\n",
    "        # 使用pool.map来并行处理每个图像\n",
    "        results = pool.map(process_image, paths)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二阶段有监督"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import uuid\n",
    "import cv2\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "root = \"/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/second_stage_train_imgs\"\n",
    "target_path = \"/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/cropped_second_stage_imgs\"\n",
    "if not os.path.exists(target_path): os.mkdir(target_path)\n",
    "# 定义处理单个图像的函数\n",
    "def process_image(data):\n",
    "    path1 = os.path.join(root, str(data[\"room_id\"]), data[\"object1\"])\n",
    "    path2 = os.path.join(root, str(data[\"room_id\"]), data[\"object2\"])\n",
    "    target_path1 = os.path.join(target_path, str(data[\"room_id\"]), data[\"object1\"])\n",
    "    target_path2 = os.path.join(target_path, str(data[\"room_id\"]), data[\"object2\"])\n",
    "    imgs1 = os.listdir(path1)\n",
    "    imgs2 = os.listdir(path2)\n",
    "    os.makedirs(target_path1, exist_ok=True)\n",
    "    os.makedirs(target_path2, exist_ok=True)\n",
    "    for path in imgs1:\n",
    "        try:\n",
    "            with open(os.path.join(path1, path), \"rb\") as f:\n",
    "                img = f.read()\n",
    "            if img is None:\n",
    "                raise ValueError(f\"无法读取图像: {path}\")\n",
    "            output_tensor = InferImages(img, client)\n",
    "            np_bbox = np.array(output_tensor.tensors['prob'].float_data)\n",
    "            bbox_shape = output_tensor.tensors['prob'].shape\n",
    "            np_bbox = np_bbox.reshape(bbox_shape)\n",
    "            if len(np_bbox) != 6:\n",
    "                continue\n",
    "            if sum(np_bbox) == 0:\n",
    "                continue\n",
    "            x1, y1, x2, y2 = np_bbox[:4].astype(int)\n",
    "            from PIL import Image, ImageDraw\n",
    "            img_np = np.frombuffer(img, dtype=np.uint8)  # 首先将字节数据转换为NumPy数组\n",
    "            img = cv2.imdecode(img_np, cv2.IMREAD_COLOR)  # 然后解码图像\n",
    "            cropped_img = img[y1:y2, x1:x2]\n",
    "            # 保存裁剪后的图像\n",
    "            cv2.imwrite(os.path.join(target_path1, path), cropped_img)\n",
    "        except Exception as e:\n",
    "            print(f\"处理图像出错: {path}, 错误: {e}\")\n",
    "\n",
    "    for path in imgs2:\n",
    "        try:\n",
    "            with open(os.path.join(path1, path), \"rb\") as f:\n",
    "                img = f.read()\n",
    "            if img is None:\n",
    "                raise ValueError(f\"无法读取图像: {path}\")\n",
    "            output_tensor = InferImages(img, client)\n",
    "            np_bbox = np.array(output_tensor.tensors['prob'].float_data)\n",
    "            bbox_shape = output_tensor.tensors['prob'].shape\n",
    "            np_bbox = np_bbox.reshape(bbox_shape)\n",
    "            if len(np_bbox) != 6:\n",
    "                continue\n",
    "            if sum(np_bbox) == 0:\n",
    "                continue\n",
    "            x1, y1, x2, y2 = np_bbox[:4].astype(int)\n",
    "            from PIL import Image, ImageDraw\n",
    "            img_np = np.frombuffer(img, dtype=np.uint8)  # 首先将字节数据转换为NumPy数组\n",
    "            img = cv2.imdecode(img_np, cv2.IMREAD_COLOR)  # 然后解码图像\n",
    "            cropped_img = img[y1:y2, x1:x2]\n",
    "            # 保存裁剪后的图像\n",
    "            cv2.imwrite(os.path.join(target_path2, path), cropped_img)\n",
    "        except Exception as e:\n",
    "            print(f\"处理图像出错: {path}, 错误: {e}\")\n",
    "\n",
    "# 使用多进程池来并行处理图像\n",
    "def parallel_process_images(paths):\n",
    "    with Pool(20) as pool:\n",
    "        # 使用pool.map来并行处理每个图像\n",
    "        results = pool.map(process_image, paths)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 imgs_dic 是一个包含图像文件路径的字典\n",
    "# paths = os.listdir(imgs_dic)\n",
    "# 调用函数开始多进程处理\n",
    "results = parallel_process_images(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114530\n"
     ]
    }
   ],
   "source": [
    "tmp = os.listdir(\"/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/croped_face/\")\n",
    "print(len(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00005acf-9c26-4cca-b0d5-46d1e83572a5.jpg', '0000ee9b-bf37-4773-9b0d-ca6045d729e0.jpg', '0001058a-e0a2-4a89-8587-9915b1dd8839.jpg', '0001507b-3d0c-4a8c-92d0-01d9ece1e9f2.jpg', '00017397-148a-4b14-8787-221f744b28d4.jpg', '00028d17-86ef-4389-afff-b93ab349ba7d.jpg', '00032153-1e9b-4c94-b0b7-ee3dbf139bd1.jpg', '000348af-a7cc-43d5-8685-a600dfc4f7af.jpg', '0004550a-c8a7-4485-86b1-89028f4c7b80.jpg', '0004ff12-0d54-4c10-ac95-ff10a342b7f3.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(tmp[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图片分为训练集和验证集完成，训练集图片数量：103077, 验证集图片数量：11453\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 图片存放的原始文件夹路径\n",
    "original_data_path = \"/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/croped_face/\"\n",
    "\n",
    "# 训练集和验证集的目标文件夹路径\n",
    "train_data_path = \"/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/croped_face/train/face\"\n",
    "val_data_path = \"/mnt/bn/data-tns-live-llm/leon/experiments/llm/face/croped_face/val/face\"\n",
    "\n",
    "# 确保目标文件夹存在\n",
    "os.makedirs(train_data_path, exist_ok=True)\n",
    "os.makedirs(val_data_path, exist_ok=True)\n",
    "\n",
    "# 获取所有图片的路径\n",
    "all_image_paths = [os.path.join(original_data_path, f) for f in os.listdir(original_data_path) if os.path.isfile(os.path.join(original_data_path, f))]\n",
    "\n",
    "# 将图片路径分为训练集和验证集，比例为 9:1\n",
    "train_paths, val_paths = train_test_split(all_image_paths, test_size=0.1, random_state=42)\n",
    "\n",
    "# 移动图片到对应的训练集和验证集文件夹\n",
    "for path in train_paths:\n",
    "    shutil.copy(path, train_data_path)\n",
    "\n",
    "for path in val_paths:\n",
    "    shutil.copy(path, val_data_path)\n",
    "\n",
    "print(f\"图片分为训练集和验证集完成，训练集图片数量：{len(train_paths)}, 验证集图片数量：{len(val_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--file\")\n",
    "    parser.add_argument(\"--dir\")\n",
    "    args = parser.parse_args([\"--dir\",\"/opt/tiger/LLM/face/data/\"])\n",
    "    client = euler.Client(FermionCore, 'sd://tns.cv.facedet_offline.service.sg1', timeout=5000)\n",
    "\n",
    "    img_file = args.file \n",
    "    img_dir = args.dir \n",
    "\n",
    "    if img_file:\n",
    "\n",
    "        with open(img_file, mode='rb') as f:\n",
    "            file_content = f.read()\n",
    "\n",
    "        output_tensor = InferImages(file_content, client)\n",
    "        np_bbox = np.array(output_tensor.tensors['bbox'].float_data)\n",
    "        bbox_shape = output_tensor.tensors['bbox'].shape\n",
    "        np_bbox = np_bbox.reshape(bbox_shape)\n",
    "        print(np_bbox)\n",
    "        \n",
    "        # visualization 可视化对其效果\n",
    "        from PIL import Image, ImageDraw\n",
    "        im = Image.open(img_file).convert('RGB')\n",
    "        drawed_im = draw_box(im, np_bbox, labels=['face',], threshold=0.4)\n",
    "        im.save('det_result.jpg', quality=95)\n",
    "\n",
    "    if img_dir:\n",
    "        file_list = os.listdir(img_dir)\n",
    "        for img_file in file_list:\n",
    "            resfile_name = '/opt/tiger/LLM/face/data/result/' + img_file\n",
    "            img_file = os.path.join(img_dir, img_file)\n",
    "            with open(img_file, mode='rb') as f:\n",
    "                file_content = f.read()\n",
    "\n",
    "            output_tensor = InferImages(file_content, client)\n",
    "            np_bbox = np.array(output_tensor.tensors['prob'].float_data)\n",
    "            bbox_shape = output_tensor.tensors['prob'].shape\n",
    "            np_bbox = np_bbox.reshape(bbox_shape)\n",
    "            print(np_bbox)\n",
    "            \n",
    "            # visualization 可视化对其效果\n",
    "            from PIL import Image, ImageDraw\n",
    "            im = Image.open(img_file).convert('RGB')\n",
    "            drawed_im = draw_box(im, np_bbox, labels=['pip',], threshold=0.6)\n",
    "            im.save(resfile_name, quality=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "checkpoint = torch.load(\"/opt/tiger/moco/moco_v1_200ep_pretrain.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoint.keys())\n",
    "print(checkpoint[\"arch\"])\n",
    "def clean_state_dict(state_dict, prefix='module.'):\n",
    "    \"\"\"\n",
    "    去掉state_dict中的指定前缀。\n",
    "    \"\"\"\n",
    "    keys = sorted([key for key in state_dict if key.startswith(prefix)])\n",
    "    for key in keys:\n",
    "        state_dict[key.replace(prefix, '')] = state_dict[key]\n",
    "        del state_dict[key]\n",
    "    return state_dict\n",
    "\n",
    "state_dict = clean_state_dict(checkpoint[\"state_dict\"],\"module.encoder_q.\")\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['object_id', 'image_urls', 'room_id']\n",
      "shape: (5, 3)\n",
      "┌─────────────────────────────────┬─────────────────────────────────┬─────────────────────┐\n",
      "│ object_id                       ┆ image_urls                      ┆ room_id             │\n",
      "│ ---                             ┆ ---                             ┆ ---                 │\n",
      "│ str                             ┆ str                             ┆ i64                 │\n",
      "╞═════════════════════════════════╪═════════════════════════════════╪═════════════════════╡\n",
      "│ tiktok_live@735665948258953088… ┆ [{\"offline_uri\":\"http://webcas… ┆ 7356659482589530886 │\n",
      "│ tiktok_live@735665948258953088… ┆ [{\"offline_uri\":\"http://webcas… ┆ 7356659482589530886 │\n",
      "│ tiktok_live@735776848083165466… ┆ [{\"offline_uri\":\"http://webcas… ┆ 7357768480831654662 │\n",
      "│ tiktok_live@735776848083165466… ┆ [{\"offline_uri\":\"http://webcas… ┆ 7357768480831654662 │\n",
      "│ tiktok_live@735934514826785873… ┆ [{\"offline_uri\":\"http://tosv.t… ┆ 7359345148267858731 │\n",
      "└─────────────────────────────────┴─────────────────────────────────┴─────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "data = pl.read_csv(\"/opt/tiger/labeled_pos_2000/part-00000-81a3d2d2-ed66-4051-96ca-b6bf309f0ccf-c000.csv\")\n",
    "print(data.columns)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
